# Week 4 Feedback: Requirements
 
**Authors:** Xavier Schneider, Greg French, Max Ku

## 1. Counterexample Problems

### Problem A_1: Identifying Missing Requirements

**Task Description:**  
Given a project and a set of requirements designed to achieve the project, identify or correct missing and incomplete requirements.

**Starter Code:**
You can find all related files here: https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback

---

### 2. Guidelines that didn't work for Problem A_1

#### Guideline 1: Try asking for concrete cases when things go wrong (Pre-Mortem Prompting)

**Guideline Definition**

Description:
Ask the LLM to assume the system failed, then work backward to identify missing requirements.

Reasoning:
Pre-mortems and misuse cases create realistic, safety/security-focused requirements tied to real
failure modes.

**Prompt and Context:**

Context: (https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemA1.md)

Prompt: Assume a data breach occurred. What privacy/security requirement was missing?

**Solution or Output generated by GitHub Copilot:** 

```
GitHub Copilot: Most likely missing: strong encryption plus strict access controls and detection.

- Encryption: Sensitive data encrypted at rest and in transit with proper key management.  
- Access control Principle of least privilege, role-based access, and multifactor authentication.  
- Logging & detection Comprehensive audit logs, real‑time monitoring/IDS, and alerting to detect exfiltration.  
- Incident response Formal breach response plan, playbooks, and notification procedures.  
- Data minimization & retention Only collect/store necessary data and securely purge when no longer needed.  
- Secure devops Timely patching, vulnerability scanning/pen testing, and secure credential handling (no plaintext secrets).  
```
...

**Analysis:**

As we can see, many of these requirements are duplicates from ProblemA1.md. Encryption for data, Secure user authentication, and Audit logs are already documented requirements. Rather than taking into account the existing requirements before generating new ones, Copilot has simply regurgitated the same information. This is likely because the guideline is LEADING, i.e. it implicitly assumes a detail/requirement is missing, even if it isn't.

---

### 3. New and Updated Guidelines that worked for Problem A_1

#### Guideline 1: Ground the LLM in current context (requirements)

**Guideline Definition**
Description:
Ensure the LLM properly takes into account the context (i.e. requirements) instead of over-comforming to the question.

Reasoning:
Grounds the LLM in the current context, ensuring duplicate requirements are not generated. s

**Prompt and Context:**

Context: (https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemA1.md)

User: Assess each security requirement. Are any of them incomplete/missing?

**Solution or Output generated by GitHub Copilot:**  

```
Summary — current `Security & Privacy` items
- Listed: Secure user authentication; Role-based authorization; Encryption for data at rest and in transit; Private and public event visibility controls; Audit logs for shared calendar changes.
- High-level: All five are good topics but written at a high level — each is incomplete and needs concrete, testable details.

What's incomplete / missing (concise)
- Authentication (incomplete): No requirements for MFA, SSO/OAuth, password storage (hashing algorithm), session management, account lockout, brute-force protection, or recovery flows.
- Authorization (incomplete): No detail on granularity (per-calendar/event ACLs), default-deny, admin roles, permission change procedures, or least-privilege enforcement.
- Encryption (incomplete): Missing specifics: required TLS versions/ciphers, HSTS, algorithm for at-rest encryption, key management/KMS, key rotation, and where encryption is applied (DB, backups, mobile cache).
- Visibility & sharing (incomplete): Lacks defaults (private vs public), ephemeral/public link controls, revocation, ICS export privacy implications, and UI affordances for sharing consent.
- Audit logging (incomplete): Missing what to log (creates/edits/deletes/shares/permissions), log integrity (append-only, tamper-evidence), retention, access controls, and alerting/SIEM integration.
- Missing security areas (not in file):
  - Data protection & privacy: data retention policy, deletion/export (right to be forgotten), PII handling, consent, compliance (GDPR/CCPA).
  - API security: authenticated APIs, OAuth scopes, rate limiting, input validation, CSRF/CORS/CSP protections.
  - Secure development lifecycle: code review, dependency scanning, vulnerability/pen-test cadence.
  - Incident response & monitoring: IDS/SIEM, alerting, breach notification timelines.
  - Secrets & key management: secure storage, rotation, least-privilege for keys.
  - Backup security: encrypted backups, access controls, restore testing.
  - Admin/privileged access controls: MFA for admins, separate admin tooling, logging of admin actions.
  - Third-party integrations: vetting, token scoping, revocation.
  - Abuse protection & DoS: rate limits, throttling, DDoS mitigations.
  - Mobile/local storage security: secure storage, encrypted local cache, push notification privacy.

Suggested concrete requirement examples
- Authentication (example): "Require MFA for all accounts; store passwords using Argon2id (parameters: m=65536,r=2,p=1); lock account after 5 failed attempts for 15 minutes; support SSO via OIDC."
- Encryption (example): "Enforce TLS 1.2+ with strong ciphers and HSTS; encrypt at rest using AES-256 with keys managed in a KMS; rotate keys every 90 days."
- Audit logging (example): "Log create/edit/delete/share/permission-change events with actor, timestamp, resource id, and old/new values; retain logs 365 days; protect logs with append-only storage and role-based access."
```
...

**Analysis:**
As we can see, rather than duplicating requirements Copilot has made suggestions for improving underspecified requirements (Authorization, Encryption) and has identified new requirements (Data protection and Privacy (GDPR), Third-party integrations, etc.). Importantly, it has clearly distiguished between pre-existing requirements and newly suggested requirements instead of mixing them together as was the case previously.

---

### Problem B: Generating Requirements From Transcript Data

### Problem B_1: Transcribing Dirty Transcript Data

**Task Description:**  
Sometimes in life, you get unlucky and have to deal with poorly formatted transcript data. Your goal in this task is to get an LLM to convert a poorly formatted transcript in which a journalist talks to a user about LLMs into a clean, well-formatted JSON representation that cleanly separates what the journalist asks from what the user says in response.

Credit:
ChatGPT 5.2 generated the original clean transcript. We altered it to make the formatting significantly worse.

**Starter Code:**  
You can find all related files here: https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback

---

### Problem B_2: Clean up the transcript

**Task Description:**  
Your next task is to clean up the transcript. Prompt the LLM to convert the text in the json file from upper case back to sentence-case (normal text). Also, ensure that the LLM outputs the text line by line in the correct order of the transcript. Save this to a new markdown file.

**Starter Code:**  
You can reuse the files from B_1 for this task.

---

### Problem B_3: Summarize the transcript

**Task Description:**  
Summarize the key points from the transcript with an emphasis on the requirements the user needs from a modern LLM system.

**Starter Code:**  
You can reuse the files from B_1 for this task.

---

### 2. Guidelines that didn't work for Problem B_1

#### Guideline 2: Capitalize role identifiers  
**Guideline Definition**
Description:
When providing context (such as a transcript), capitalize the role identifiers such as “INTER
VIEWER” and “INTERVIEWEE”.

Reasoning:
When reading transcripts, LLMs can sometimes misclassify which person was responsible for saying
what, which leads to all sorts of errors. Luckily, capitalizing role identifiers has been found to
significantly reduce this classification error.

**Prompt and Context:**  
Prompt: Can you parse out this transcript into a JSON file, separating out what the journalist says from what the user says

Context: (https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemB1.md)

**Solution or Output generated by GitHub Copilot:**  
Copilot created a file called transcript.json with the following:  
```
{  
  "journalist": [  
    "THANKS FOR MEETING WITH ME. YOU’VE BEEN USING LARGE LANGUAGE MODELS FOR A WHILE NOW—HOW WOULD YOU DESCRIBE THEM TO SOMEONE WHO’S NEVER HEARD OF THEM?",  
    "WHAT MADE YOU START USING THEM?",  
    "NEWSPAPER WRITING AND PROMPT ENGINEERING",  
    "DO YOU TRUST WHAT THEY TELL YOU?",  
    "WHAT DO YOU THINK IS THEIR BIGGEST STRENGTH?",  
    "AND THE BIGGEST CONCERN?",  
    "FINAL THOUGHTS?"  
  ],  
  "user": [ 
    "I USUALLY SAY THEY’RE LIKE VERY ADVANCED TEXT PREDICTORS. THEY DON’T UNDERSTAND IN A HUMAN WAY, BUT THEY’RE INCREDIBLY GOOD AT RECOGNIZING PATTERNS IN LANGUAGE AND GENERATING RESPONSES THAT FEEL MEANINGFUL.",  
    "AT FIRST, CURIOSITY. I WORK WITH A LOT OF TECHNICAL MATERIAL, AND I WANTED SOMETHING THAT COULD HELP ME BRAINSTORM, SUMMARIZE, AND EXPLAIN THINGS FASTER. ONCE I SAW HOW MUCH TIME IT SAVED, IT BECAME PART OF MY DAILY WORKFLOW.",  
    "HERE ARE 2 THINGS I WORK ON AS A",  
    "NOT BLINDLY. THEY’RE IMPRESSIVE, BUT THEY CAN BE CONFIDENTLY WRONG. I TREAT THEM LIKE A SMART ASSISTANT THAT STILL NEEDS FACT-CHECKING, ESPECIALLY FOR ANYTHING IMPORTANT.",  
    "ACCESSIBILITY. THEY MAKE COMPLEX IDEAS EASIER TO APPROACH. YOU CAN ASK A QUESTION IN PLAIN LANGUAGE AND GET A CLEAR EXPLANATION, WHICH LOWERS THE BARRIER TO LEARNING.",  
    "THAT PEOPLE MIGHT ASSUME THEY’RE OBJECTIVE OR ALWAYS CORRECT. THEY REFLECT THE DATA THEY’RE TRAINED ON, SO BIAS AND ERRORS ARE REAL ISSUES.",  
    "I THINK LLMS ARE TOOLS, NOT REPLACEMENTS FOR THINKING. USED CAREFULLY, THEY CAN AMPLIFY WHAT PEOPLE ALREADY KNOW—BUT THEY SHOULDN’T REPLACE HUMAN JUDGMENT."  
  ]  
}  
```

...

**Analysis:**

As we can see, the LLM fails at a tricky edge case in which the user states that they themselves are a journalist and what they work on as a journalist. Any human reading this can infer what the user is saying and understand that the text is coming from a human, but the LLM picks this up as something the journalist is saying instead, role capitalization did not help.

---

### 3. New and Updated Guidelines that worked for Problem B_1

#### Guideline 2: Add Parse-specific Instructions

**Guideline Definition**
Description:
When parsing, provide instructions that are specific to the document you are attempting to parse (human in the loop).

Reasoning:
Sometimes formatting can be ambiguous, or else very tricky. In such cases, underspecification yields ambiguous and confusing results.

**Prompt and Context:**  
Prompt:  
Can you parse out this transcript into a JSON file, separating out what the journalist says from what the user says. Be careful about sentences that look like it's a journalist/user saying something new, but it's actually a continuation of the previous sentence. The user being interviewed may also be a journalist. For example, the user could say "as a journalist:", and that will be a perfectly valid statement coming from the user

Context:  
A feedback.md file containing the transcript was the sole file in the repo when testing.

**Solution or Output generated by GitHub Copilot:**  
Copilot created a file called transcript_parsed.json with the following:
``` 
[  
  {  
    "speaker": "JOURNALIST",  
    "text": "THANKS FOR MEETING WITH ME. YOU’VE BEEN USING LARGE LANGUAGE MODELS FOR A WHILE NOW—HOW WOULD YOU DESCRIBE THEM TO SOMEONE WHO’S NEVER HEARD OF THEM?"  
  },  
  {  
    "speaker": "USER",  
    "text": "I USUALLY SAY THEY’RE LIKE VERY ADVANCED TEXT PREDICTORS. THEY DON’T UNDERSTAND IN A HUMAN WAY, BUT THEY’RE INCREDIBLY GOOD AT RECOGNIZING PATTERNS IN LANGUAGE AND GENERATING RESPONSES THAT FEEL MEANINGFUL."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "WHAT MADE YOU START USING THEM?"  
  },  
  {  
    "speaker": "USER",  
    "text": "AT FIRST, CURIOSITY. I WORK WITH A LOT OF TECHNICAL MATERIAL, AND I WANTED SOMETHING THAT COULD HELP ME BRAINSTORM, SUMMARIZE, AND EXPLAIN THINGS FASTER. ONCE I SAW HOW MUCH TIME IT SAVED, IT BECAME PART OF MY DAILY WORKFLOW."  
  },  
  {  
    "speaker": "USER",  
    "text": "HERE ARE 2 THINGS I WORK ON AS A JOURNALIST: NEWSPAPER WRITING AND PROMPT ENGINEERING"  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "DO YOU TRUST WHAT THEY TELL YOU?"  
  },  
  {  
    "speaker": "USER",  
    "text": "NOT BLINDLY. THEY’RE IMPRESSIVE, BUT THEY CAN BE CONFIDENTLY WRONG. I TREAT THEM LIKE A SMART ASSISTANT THAT STILL NEEDS FACT-CHECKING, ESPECIALLY FOR ANYTHING IMPORTANT."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "WHAT DO YOU THINK IS THEIR BIGGEST STRENGTH?"  
  },  
  {  
    "speaker": "USER",  
    "text": "ACCESSIBILITY. THEY MAKE COMPLEX IDEAS EASIER TO APPROACH. YOU CAN ASK A QUESTION IN PLAIN LANGUAGE AND GET A CLEAR EXPLANATION, WHICH LOWERS THE BARRIER TO LEARNING."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "AND THE BIGGEST CONCERN?"  
  },  
  {  
    "speaker": "USER",  
    "text": "THAT PEOPLE MIGHT ASSUME THEY’RE OBJECTIVE OR ALWAYS CORRECT. THEY REFLECT THE DATA THEY’RE TRAINED ON, SO BIAS AND ERRORS ARE REAL ISSUES."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "FINAL THOUGHTS?"  
  },  
  {  
    "speaker": "USER",  
    "text": "I THINK LLMS ARE TOOLS, NOT REPLACEMENTS FOR THINKING. USED CAREFULLY, THEY CAN AMPLIFY WHAT PEOPLE ALREADY KNOW—BUT THEY SHOULDN’T REPLACE HUMAN JUDGMENT."  
  }  
]
```

...

**Analysis:**

As we can see, once the LLM is given additional instructions / examples of an edge case to look out for, it performs the task flawlessly. In this case, the prompter would need to know of these potential edge cases in advance and let the LLM know about them. If they don't, it could result in a catastrophic parsing mistake by the LLM.

*Note that after the transcript was cleaned, Copilot performed adequately on B3 (requirement generation)

---

### Problem C_1: Eliciting new requirements

**Task Description:**  
Collaborate with copilot to generate a set of requirements for an online store.

**Starter Code:**  
You can find all related files here: https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback

---

### 2. Guidelines that didn't work for Problem C_1

#### Guideline 3:  Provide few-shot examples 

**Guideline Definition**
Description: 
When attempting to describe desired behavior of a program or system, give 1-3 examples of desired output.

Reasoning:
Few-shot examples have been shown to reliably improve adherence to format and improve performance in LLMs. These examples also double as tests for your requirements, increasing verifi- ability. In addition, examples are one of the strongest methods of enforcing structure in output, making it more likely to follow that structure and read output.

**Prompt and Context:**

Prompt:

Generate requirements of exact format:
[Requirement title] - [Requirement type] [Brief requirement description]

Example:
User Login - Functional The system shall allow users to log in using email and password.

Generate requirements for an online store.

**Solution or Output generated by GitHub Copilot:**

Output of Copliot
```
User Authentication - Functional The system shall allow users to register and log in using email and password.
User Profile Management - Functional The system shall allow users to view and update their profile information.
Product Catalog - Functional The system shall display a searchable and browsable catalog of products with images, descriptions, prices, and availability.
Product Search - Functional The system shall provide keyword search with filters for category, price, brand, and rating.
Product Filtering and Sorting - Functional The system shall allow users to filter and sort product listings by price, popularity, rating, and relevance.
Product Details - Functional The system shall display detailed product pages including specifications, reviews, and related products.
Shopping Cart - Functional The system shall allow users to add, update, and remove products in a persistent shopping cart.
Guest Checkout - Functional The system shall allow users to complete purchases without creating an account.
Checkout Flow - Functional The system shall collect shipping, billing, and payment information and confirm orders before processing.
Payment Processing - Functional The system shall integrate with at least one payment gateway to securely process credit card and digital wallet payments.
Order Management - Functional The system shall create, track, and display order statuses (placed, confirmed, shipped, delivered, canceled).
Inventory Management - Functional The system shall decrement product inventory on confirmed purchases and prevent overselling.
Shipping Calculation - Functional The system shall calculate shipping costs and estimated delivery times based on destination and chosen shipping method.
Tax Calculation - Functional The system shall calculate applicable taxes based on buyer location and product tax rules.
Returns and Refunds - Functional The system shall allow users to request returns and process refunds according to store policies.
Promotions and Discounts - Functional The system shall support promotional codes, percentage/amount discounts, and time-limited offers.
Reviews and Ratings - Functional The system shall allow authenticated users to submit product reviews and ratings.
Notifications - Functional The system shall send order confirmations, shipping updates, and other transactional emails to users.
Admin Dashboard - Functional The system shall provide administrators with dashboards to manage products, orders, users, and promotions.
API Access - Functional The system shall expose a versioned RESTful API for product, cart, and order operations.
Performance - Non-functional The system shall respond to 95% of user-facing requests within 300ms under normal load.
Scalability - Non-functional The system shall scale horizontally to handle peak traffic spikes without downtime.
Availability - Non-functional The system shall maintain 99.9% uptime excluding scheduled maintenance.
Security - Non-functional The system shall store sensitive data encrypted at rest and use TLS for all data in transit.
Privacy/Compliance - Non-functional The system shall comply with applicable data protection regulations (e.g., GDPR) and provide data deletion on user request.
Accessibility - Non-functional The system shall meet WCAG 2.1 AA accessibility standards for the public storefront.
Localization - Non-functional The system shall support multiple languages and currencies selectable by the user.
Logging and Auditing - Non-functional The system shall log security-relevant events and provide audit trails for administrative actions.
Backup and Recovery - Non-functional The system shall perform daily backups and support recovery within defined RTO/RPO targets.
Monitoring and Alerts - Non-functional The system shall monitor key metrics and alert operations teams on critical failures.
Third-Party Integrations - Functional The system shall integrate with third-party services for shipping carriers, tax calculators, and analytics.
```

**Analysis:**
As we can see, the general structure is reasonable, but the requirements themselves are being constrained by our template. While this is by design (we provided the template and few shot example), it is nonetheless a fundamental drawback of few shot examples, in that they bias the model to a particular kind of output.

### 3. New and Updated Guidelines that worked for Problem C_1

#### Guideline 3: Prefer Open-Ended Prompting for Early-Stage Elicitation
**Guideline Definition**
Description:

During early-stage requirements elicitation, use open-ended prompts without few-shot examples. Introduce few-shot examples only after the problem space is well understood and a fixed output structure is required.

Reasoning:

Few-shot examples enforce structure but can overly constrain the model, leading to shallow and repetitive requirements in exploratory tasks. Open-ended prompting allows broader reasoning and more thoughtful requirement discovery before formalization.

**Prompt and Context:**

Prompt: Generate a list of requirements for an online store. Use any formatting you would like.

**Solution or Output generated by GitHub Copilot:**

```
Functional Requirements

User Accounts: Register, login (email/social), password reset, profile management.
Product Catalog: Create/read/update/delete (CRUD) products with variants, images, categories, tags.
Search & Filters: Full-text search, faceted filters (price, category, brand, rating), sort options.
Product Detail: Show descriptions, specs, reviews, related items, inventory status.
Shopping Cart: Add/remove/update quantities, persist across devices/sessions.
Checkout Flow: Multi-step checkout (billing, shipping, review), guest checkout option.
Payment Processing: Integrate with payment gateways (card, Apple/Google Pay, PayPal), support refunds.
Order Management (Customer): Order history, order detail, tracking, order cancellation where allowed.
Admin Order Management: View/update orders, manage statuses, refunds, shipping labels.
Inventory Management: Track stock levels, backorder handling, low-stock alerts.
Pricing & Promotions: Coupons, discounts, bulk/pricing rules, scheduled promotions.
Shipping & Taxes: Rate calculation, multiple shipping methods, tax calculation by region.
Catalog Management (Admin): Bulk import/export, variant management, tagging, SEO fields.
Customer Communications: Transactional emails, SMS/push notifications for order updates.
Reviews & Ratings: Submit, moderate, display product reviews.
Customer Support Tools: Support ticketing or integration with existing helpdesk.
Wishlist & Save-for-later: Save items, move to cart.
Multi-store / Multi-vendor (optional): Support multiple storefronts or sellers if required.
Localization: Multi-language content and currency selection.
Analytics & Reporting: Sales reports, conversion metrics, product performance.
Non-Functional Requirements

Performance: Page load < 2s for product pages under typical load; checkout latency targets.
Scalability: Handle X concurrent users/orders (specify target) with horizontal scaling.
Availability: 99.9% monthly uptime (or defined SLA).
Security: OWASP Top 10 mitigations, secure session management, rate-limiting, input validation.
Payment Compliance: PCI-DSS scope minimized (use tokenization/hosted checkout).
Privacy: GDPR/CCPA compliance, user data export/delete, consent for marketing.
Accessibility: WCAG 2.1 AA compliance for customer-facing pages.
Reliability & Recovery: Backups, RTO/RPO targets, graceful degradation.
Maintainability: Modular codebase, documented APIs, test coverage targets.
Monitoring & Logging: Structured logs, alerting for errors and SLA breaches.
SEO & Crawlability: Server-side rendering or pre-rendering for product pages, sitemap generation.
Mobile Responsiveness: Full functionality on mobile browsers; mobile-first layout.
Internationalization: Currency formatting, locale-aware dates/times.
Rate Limits & Throttling: Prevent abuse and protect services.
Business & Compliance Requirements

Taxes & Reporting: Accurate tax calculation per jurisdiction; exportable tax reports.
Legal & Policies: Terms of service, privacy policy, return/refund policy published and enforced.
Fraud Prevention: Anti-fraud checks, velocity rules, manual review workflows.
Pricing & Invoicing: Invoice generation, receipts, fiscal requirements per region.
Auditability: Immutable audit logs for orders, price changes, refunds.
Customer Data Portability: Allow customers to download or delete their data.
SLAs & Support: Defined response/resolution times for incidents and customer queries.
Payment Reconciliation: Reconcile gateway payouts with orders, support chargeback handling.
Regulatory Compliance: Industry-specific regulations (e.g., VAT, export controls) as applicable.
Localization of Legal Requirements: Local consumer protection rules for each market.
Operational & Integration Requirements

Third-party Integrations: ERP, CRM, shipping carriers, tax services, analytics, marketing platforms.
Environments: Separate dev/staging/production with deployment promotion process.
CI/CD: Automated tests and deployments with rollback capability.
Caching & CDN: Use CDN for assets and caching for high-read pages.
Data Migration: Tools for migrating legacy product/customer/order data.
Scaling Plan: Runbook for traffic spikes, Black Friday preparation.
Acceptance Criteria & Metrics

User journey tests: End-to-end checkout succeeds for typical purchase (unit+integration+E2E).
Performance tests: Meet page load and throughput targets under defined load tests.
Security tests: Pass periodic penetration tests and vulnerability scans.
Accessibility tests: Automated and manual checks achieving WCAG 2.1 AA.
Business KPIs: Track conversion rate, average order value, cart abandonment rate.
```

**Analysis:**
While few-shot examples improve adherence to a specified format, we observe that they can overly constrain the model in open-ended requirements elicitation tasks. In our experiment, providing a strict few-shot template led Copilot to generate shallow, repetitive requirements focused mainly on basic functionality. In contrast, an open-ended prompt without few-shot examples produced more diverse and thoughtful requirements, such as user journey tests. This demonstrates that few-shot prompting does not reliably improve performance, but instead trades exploratory quality for structural conformity. Credit: ChatGPT 5.2 assisted in the writing of this analysis.