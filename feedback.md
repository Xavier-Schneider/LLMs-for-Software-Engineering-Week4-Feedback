# Week 4 Feedback: Requirements
 
**Authors:** Xavier Schneider, Greg French, Max Ku

## 1. Counterexample Problems

### Problem A_1: [Identifying Missing Requirements]

**Task Description:**  
Given a project and a set of requirements designed to achieve the project, identify or correct missing and incomplete requirements.

**Starter Code:**
[Requirements file](https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemA1.md)

---

### 2. Guidelines that didn't work for Problem A_1

#### Guideline 1: [Try asking for concrete cases when things go wrong (Pre-Mortem Prompting)]

**Guideline Definition**

Description:
Ask the LLM to assume the system failed, then work backward to identify missing requirements.

Reasoning:
Pre-mortems and misuse cases create realistic, safety/security-focused requirements tied to real
failure modes.

**Prompt and Context:**

Context: (https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemA1.md)

Prompt: Assume a data breach occurred. What privacy/security requirement was missing?

**Solution or Output generated by GitHub Copilot:**  

GitHub Copilot: Most likely missing: strong encryption plus strict access controls and detection.

- Encryption: Sensitive data encrypted at rest and in transit with proper key management.  
- Access control Principle of least privilege, role-based access, and multifactor authentication.  
- Logging & detection Comprehensive audit logs, real‑time monitoring/IDS, and alerting to detect exfiltration.  
- Incident response Formal breach response plan, playbooks, and notification procedures.  
- Data minimization & retention Only collect/store necessary data and securely purge when no longer needed.  
- Secure devops Timely patching, vulnerability scanning/pen testing, and secure credential handling (no plaintext secrets).  

...

**Analysis:**

As we can see, many of these requirements are duplicates from ProblemA1.md. Encryption for data, Secure user authentication, and Audit logs are already documented requirements. This guideline suffers from underspecification - i.e. rather than taking into account the existing requirements before generating new ones, Copilot has simply regurgitated the same information.

---

### 3. New and Updated Guidelines that worked for Problem A_1

#### Guideline 1: [Try asking for an assement of missing/incomplete requirements]
**Prompt and Context:**

Context: (https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback/blob/main/ProblemA1.md)

User: Assess each security requirement. Are any of them incomplete/missing?

**Solution or Output generated by GitHub Copilot:**  


GitHub Copilot: I'll create a short plan (todo list) for reviewing the security requirements.

Summary — current `Security & Privacy` items
- Listed: Secure user authentication; Role-based authorization; Encryption for data at rest and in transit; Private and public event visibility controls; Audit logs for shared calendar changes.
- High-level: All five are good topics but written at a high level — each is incomplete and needs concrete, testable details.

What's incomplete / missing (concise)
- Authentication (incomplete): No requirements for MFA, SSO/OAuth, password storage (hashing algorithm), session management, account lockout, brute-force protection, or recovery flows.
- Authorization (incomplete): No detail on granularity (per-calendar/event ACLs), default-deny, admin roles, permission change procedures, or least-privilege enforcement.
- Encryption (incomplete): Missing specifics: required TLS versions/ciphers, HSTS, algorithm for at-rest encryption, key management/KMS, key rotation, and where encryption is applied (DB, backups, mobile cache).
- Visibility & sharing (incomplete): Lacks defaults (private vs public), ephemeral/public link controls, revocation, ICS export privacy implications, and UI affordances for sharing consent.
- Audit logging (incomplete): Missing what to log (creates/edits/deletes/shares/permissions), log integrity (append-only, tamper-evidence), retention, access controls, and alerting/SIEM integration.
- Missing security areas (not in file):
  - Data protection & privacy: data retention policy, deletion/export (right to be forgotten), PII handling, consent, compliance (GDPR/CCPA).
  - API security: authenticated APIs, OAuth scopes, rate limiting, input validation, CSRF/CORS/CSP protections.
  - Secure development lifecycle: code review, dependency scanning, vulnerability/pen-test cadence.
  - Incident response & monitoring: IDS/SIEM, alerting, breach notification timelines.
  - Secrets & key management: secure storage, rotation, least-privilege for keys.
  - Backup security: encrypted backups, access controls, restore testing.
  - Admin/privileged access controls: MFA for admins, separate admin tooling, logging of admin actions.
  - Third-party integrations: vetting, token scoping, revocation.
  - Abuse protection & DoS: rate limits, throttling, DDoS mitigations.
  - Mobile/local storage security: secure storage, encrypted local cache, push notification privacy.

Suggested concrete requirement examples
- Authentication (example): "Require MFA for all accounts; store passwords using Argon2id (parameters: m=65536,r=2,p=1); lock account after 5 failed attempts for 15 minutes; support SSO via OIDC."
- Encryption (example): "Enforce TLS 1.2+ with strong ciphers and HSTS; encrypt at rest using AES-256 with keys managed in a KMS; rotate keys every 90 days."
- Audit logging (example): "Log create/edit/delete/share/permission-change events with actor, timestamp, resource id, and old/new values; retain logs 365 days; protect logs with append-only storage and role-based access."

...

**Analysis:**
As we can see, rather than duplicating requirements, Copilot has made suggestions for improving underspecified requirements (Authorization, Encryption) and has identified new requirements (Data protection and Privacy (GDPR), Third-party integrations, etc.). Importantly, it has clearly distiguished between pre-existing requirements and newly suggested requirements instead of mixing them together as was the case previously.

---

### Problem B_1: Transcribing Dirty Transcript Data

**Task Description:**  
Sometimes in life, you get unlucky and have to deal with poorly formatted transcript data. Your goal in this task is to get an LLM to convert a poorly formatted transcript in which a journalist talks to a user about LLMs into a clean, well-formatted JSON representation that cleanly separates what the journalist asks from what the user says in response.

Credit:
ChatGPT 5.2 generated the original clean transcript. We altered it to make the formatting significantly worse.

**Starter Code:**  
You can find all related files here: https://github.com/Xavier-Schneider/LLMs-for-Software-Engineering-Week4-Feedback

---

### Problem B_2: Clean up the transcript

**Task Description:**  
Your next task is to clean up the transcript. Prompt the LLM to convert the text in the json file from upper case back to sentence-case (normal text). Also, ensure that the LLM outputs the text line by line in the correct order of the transcript. Save this to a new markdown file.

**Starter Code:**  
You can reuse the files from B_1 for this task.

---

### Problem B_3: Summarize the transcript

**Task Description:**  
Summarize the key points from the transcript with an emphasis on the requirements the user needs from a modern LLM system.

**Starter Code:**  
You can reuse the files from B_1 for this task.

---

### 2. Guidelines that didn't work for Problem B_1

#### Guideline 1: [Capitalize role identifiers]  
**Prompt and Context:**  
Prompt:  
Can you parse out this transcript into a JSON file, separating out what the journalist says from what the user says

Context:  
A feedback.md file containing the transcript was the sole file in the repo when testing.

**Solution or Output generated by GitHub Copilot:**  
Copilot created a file called transcript.json with the following:  
{  
  "journalist": [  
    "THANKS FOR MEETING WITH ME. YOU’VE BEEN USING LARGE LANGUAGE MODELS FOR A WHILE NOW—HOW WOULD YOU DESCRIBE THEM TO SOMEONE WHO’S NEVER HEARD OF THEM?",  
    "WHAT MADE YOU START USING THEM?",  
    "NEWSPAPER WRITING AND PROMPT ENGINEERING",  
    "DO YOU TRUST WHAT THEY TELL YOU?",  
    "WHAT DO YOU THINK IS THEIR BIGGEST STRENGTH?",  
    "AND THE BIGGEST CONCERN?",  
    "FINAL THOUGHTS?"  
  ],  
  "user": [ 
    "I USUALLY SAY THEY’RE LIKE VERY ADVANCED TEXT PREDICTORS. THEY DON’T UNDERSTAND IN A HUMAN WAY, BUT THEY’RE INCREDIBLY GOOD AT RECOGNIZING PATTERNS IN LANGUAGE AND GENERATING RESPONSES THAT FEEL MEANINGFUL.",  
    "AT FIRST, CURIOSITY. I WORK WITH A LOT OF TECHNICAL MATERIAL, AND I WANTED SOMETHING THAT COULD HELP ME BRAINSTORM, SUMMARIZE, AND EXPLAIN THINGS FASTER. ONCE I SAW HOW MUCH TIME IT SAVED, IT BECAME PART OF MY DAILY WORKFLOW.",  
    "HERE ARE 2 THINGS I WORK ON AS A",  
    "NOT BLINDLY. THEY’RE IMPRESSIVE, BUT THEY CAN BE CONFIDENTLY WRONG. I TREAT THEM LIKE A SMART ASSISTANT THAT STILL NEEDS FACT-CHECKING, ESPECIALLY FOR ANYTHING IMPORTANT.",  
    "ACCESSIBILITY. THEY MAKE COMPLEX IDEAS EASIER TO APPROACH. YOU CAN ASK A QUESTION IN PLAIN LANGUAGE AND GET A CLEAR EXPLANATION, WHICH LOWERS THE BARRIER TO LEARNING.",  
    "THAT PEOPLE MIGHT ASSUME THEY’RE OBJECTIVE OR ALWAYS CORRECT. THEY REFLECT THE DATA THEY’RE TRAINED ON, SO BIAS AND ERRORS ARE REAL ISSUES.",  
    "I THINK LLMS ARE TOOLS, NOT REPLACEMENTS FOR THINKING. USED CAREFULLY, THEY CAN AMPLIFY WHAT PEOPLE ALREADY KNOW—BUT THEY SHOULDN’T REPLACE HUMAN JUDGMENT."  
  ]  
}  

...

**Analysis:**

As we can see, the LLM fails at a tricky edge case in which the user states that they themselves are a journalist and what they work on as a journalist. Any human reading this can infer what the user is saying and understand that the text is coming from a human, but the LLM picks this up as something the journalist is saying instead.

---

### 3. New and Updated Guidelines that worked for Problem B_1

#### Guideline 1: [Add Parse-specific Instructions]  
**Prompt and Context:**  
Prompt:  
Can you parse out this transcript into a JSON file, separating out what the journalist says from what the user says. Be careful about sentences that look like it's a journalist/user saying something new, but it's actually a continuation of the previous sentence. The user being interviewed may also be a journalist. For example, the user could say "as a journalist:", and that will be a perfectly valid statement coming from the user

Context:  
A feedback.md file containing the transcript was the sole file in the repo when testing.

**Solution or Output generated by GitHub Copilot:**  
Copilot created a file called transcript_parsed.json with the following:  
[  
  {  
    "speaker": "JOURNALIST",  
    "text": "THANKS FOR MEETING WITH ME. YOU’VE BEEN USING LARGE LANGUAGE MODELS FOR A WHILE NOW—HOW WOULD YOU DESCRIBE THEM TO SOMEONE WHO’S NEVER HEARD OF THEM?"  
  },  
  {  
    "speaker": "USER",  
    "text": "I USUALLY SAY THEY’RE LIKE VERY ADVANCED TEXT PREDICTORS. THEY DON’T UNDERSTAND IN A HUMAN WAY, BUT THEY’RE INCREDIBLY GOOD AT RECOGNIZING PATTERNS IN LANGUAGE AND GENERATING RESPONSES THAT FEEL MEANINGFUL."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "WHAT MADE YOU START USING THEM?"  
  },  
  {  
    "speaker": "USER",  
    "text": "AT FIRST, CURIOSITY. I WORK WITH A LOT OF TECHNICAL MATERIAL, AND I WANTED SOMETHING THAT COULD HELP ME BRAINSTORM, SUMMARIZE, AND EXPLAIN THINGS FASTER. ONCE I SAW HOW MUCH TIME IT SAVED, IT BECAME PART OF MY DAILY WORKFLOW."  
  },  
  {  
    "speaker": "USER",  
    "text": "HERE ARE 2 THINGS I WORK ON AS A JOURNALIST: NEWSPAPER WRITING AND PROMPT ENGINEERING"  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "DO YOU TRUST WHAT THEY TELL YOU?"  
  },  
  {  
    "speaker": "USER",  
    "text": "NOT BLINDLY. THEY’RE IMPRESSIVE, BUT THEY CAN BE CONFIDENTLY WRONG. I TREAT THEM LIKE A SMART ASSISTANT THAT STILL NEEDS FACT-CHECKING, ESPECIALLY FOR ANYTHING IMPORTANT."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "WHAT DO YOU THINK IS THEIR BIGGEST STRENGTH?"  
  },  
  {  
    "speaker": "USER",  
    "text": "ACCESSIBILITY. THEY MAKE COMPLEX IDEAS EASIER TO APPROACH. YOU CAN ASK A QUESTION IN PLAIN LANGUAGE AND GET A CLEAR EXPLANATION, WHICH LOWERS THE BARRIER TO LEARNING."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "AND THE BIGGEST CONCERN?"  
  },  
  {  
    "speaker": "USER",  
    "text": "THAT PEOPLE MIGHT ASSUME THEY’RE OBJECTIVE OR ALWAYS CORRECT. THEY REFLECT THE DATA THEY’RE TRAINED ON, SO BIAS AND ERRORS ARE REAL ISSUES."  
  },  
  {  
    "speaker": "JOURNALIST",  
    "text": "FINAL THOUGHTS?"  
  },  
  {  
    "speaker": "USER",  
    "text": "I THINK LLMS ARE TOOLS, NOT REPLACEMENTS FOR THINKING. USED CAREFULLY, THEY CAN AMPLIFY WHAT PEOPLE ALREADY KNOW—BUT THEY SHOULDN’T REPLACE HUMAN JUDGMENT."  
  }  
]

...

**Analysis:**

As we can see, once the LLM is given additional instructions / examples of an edge case to look out for, it performs the task flawlessly. In this case, the prompter would need to know of these potential edge cases in advance and let the LLM know about them. If they don't, it could result in a catastrophic parsing mistake by the LLM.

---